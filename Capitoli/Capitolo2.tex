L'applicazione delle tecniche di Clustering su pagine Web non è un nuovo campo di ricerca. La maggior parte delle metodologie che si trovano in letteratura sono state usate per raggrupparle.
\\\\
Tuttavia queste ricerche sono state indirizzate sul Clustering di pagine provenienti da diversi siti Web, trascurando quelle di uno specifico sito. Gli hyperlink, infatti, hanno significati diversi in base al dominio di destinazione: se la pagina puntata si trova nello stesso sito Web, allora il collegamento avrà funzione di organizzazione dei contenuti; altrimenti, se la pagina di destinazione è esterna, avrà la funzionalità di riferirsi a pagine che probabilmente avranno contenuti simili.
\\\\
Gli algoritmi di Clustering esistenti si classificano in quattro categorie in base alle informazioni usate per raggruppare le pagine Web:
\begin{itemize}
	\item \textbf{Algoritmi di Clustering basati sul contenuto testuale}. Questa tipologia di algoritmi considerano le pagine come dei documenti testuali. Questo è il caso di \cite{Zamir,Chehreghani,Haveliwala,Anami}, dove la distribuzione delle parole è usata per scoprire insiemi appropriati di pagine Web correlate. Il vantaggio di questo approccio è che molti strumenti di Clustering, basati sul modello dello spazio vettoriale, possono essere direttamente applicabili. Lo svantaggio è che questi algoritmi falliscono quando devono essere appresi modelli accurati, a causa della natura non controllata ed eterogenea dei contenuti delle pagine Web. 
	\\
	I tradizionali algoritmi di Clustering si basano sull'assunto che i documenti testuali condividono stili di scrittura consistenti, dando abbastanza informazioni contestuali, sono chiari e completamente non strutturati, sono indipendenti e identicamente distribuiti. Queste limitazioni sono più marcate per il Clustering di pagine Web di differenti siti. Infatti, le pagine aventi stesso argomento potrebbero essere contestualmente differenti: potrebbero avere un contenuto informativo simile inserito in elementi Web aventi diverse regole semantiche (i.e. tabelle o menu di navigazione) e differenti funzionalità (i.e. link, pulsanti, immagini).
	\item \textbf{Algoritmi di Clustering basati sui Web log}. In questa tipologia si trovano algoritmi che analizzano ed estraggono informazioni a partire dai Web Log, che vengono usati per raggruppare pagine Web in funzione a schemi di comportamento degli utenti durante la navigazione in un determinato sito. In \cite{shahabi97knowledge} l'autore considera la cronologia di navigazione ed il tempo di visualizzazione di ogni pagina come informazioni per raggruppare i profili degli utenti. I cluster estratti possono essere usati per migliorare l'esperienza di navigazione degli utenti \cite{Crabtree}: così facendo, per esempio, è possibile migliorare la navigazione del sito Web di un dipartimento, differenziandola in base al profilo utente. Questa operazione di Clustering, tuttavia, può portare a difficoltà: ad ogni profilo utente potrebbero corrispondere cluster differenti di pagine Web.
	\item \textbf{Algoritmi di Clustering basati sulla struttura HTML}. Le pagine Web, a differenza dei documenti testuali, sono caratterizzate da proprietà strutturali come i tag HTML, che permettono di definire la loro rappresentazione strutturale. E' stato provato da \cite{crescenzi,bohunsky,lin,zhu} che l'informazione strutturale fornisce una differente e complementare rappresentazione rispetto a quella testuale. Questi tipi di algoritmi di Clustering hanno il vantaggio di considerare l'informazione strutturale e visuale inserita nei tag HTML, che viene ignorata dall'approccio testuale. I tag HTML sono i responsabili della visualizzazione dei dati all'interno di una pagina Web. Per questo è possibile avere pagine aventi lo stesso tipo di semantica (e.g. pagine di professori) ma codificate e visualizzate in maniera differente. Per esempio, i dati strutturati inseriti in tabelle (aventi come tag HTML $<$table$>$) oppure in liste (aventi come tag HTML $<$ul$>$) avranno una simile visualizzazione. Questo abbassa la qualità dei cluster generati.
	\\
	Per risolvere questa sfida, gli autori di \cite{crescenzi,bohunsky} propongono di usare l'informazione associata ai tag HTML. In \cite{bohunsky} viene effettuato un processo di Clustering basandosi solo sulle proprietà visuali delle pagine Web. L'obiettivo di questo approccio è quello di raggruppare le pagine Web che hanno una visualizzazione simile, trascurando il contenuto e la struttura HTML. In \cite{crescenzi} il layout e le proprietà visuali associati ai tag HTML vengono usati per caratterizzare la struttura dell'intera pagina Web, mentre le collezioni di hyperlink vengono considerate per trovare pagine avente una rappresentazione strutturale simile.
	\item \textbf{Algoritmi di Clustering basati sulla struttura ad hyperlink}. Anche la struttura ad hyperlink che interconnettono le pagine Web caratterizzano le loro proprietà strutturali. Gli algoritmi basati sulla struttura ad hyperlink lavorano su una collegata collezione di pagine Web. L'idea di base è che quando due pagine web sono connesse tramite un link esiste una relazione tra le due. Da qui sarà possibile effettuare il Clustering. In generale, questi metodi \cite{Cristo2003} usano solo link diretti tra le pagine e, da questi, vengono usate/definite alcune misure di similarità, come la somiglianza bibliografica \cite{kessler} e le co-citazioni \cite{small}.
	\\
	In \cite{fisher}, l'autore spiega come questa tipologia di algoritmi di Clustering lavorano bene quando la struttura ad hyperlink è densa e senza link rumore. Essi restituiscono risultati di bassa qualità per pagine Web aventi un numero insufficiente di link, sia che portino a pagine appartenenti allo stesso sito Web, sia che puntino a pagine di siti differenti. Inoltre, non tutti i link hanno stessa importanza nel processo di Clustering: le pagine sono spesso arricchite di link rumore come gli short-cut hyperlink (i link scorciatoia). Per superare questo problema, molti algoritmi combinano le informazioni ricavate dal contenuto con quelle dei link \cite{lin,He01webdocument,Modha,Wang,Drost2006,Angelova}.
	\\
	Inoltre, in \cite{He01webdocument} l'autore ha risolto il problema dei link rumore considerando solo gli hyperlink tra pagine web di argomento simile e co-citate. Successivamente, è stato applicato un tradizionale algoritmo di Clustering basato sul partizionamento del grafo. In particolare, è stato assegnato un peso che combina la similarità di contenuto e la co-citazione per ogni arco $(i, j)$, dove $i$ e $j$ sono le pagine collegate del grafo del sito Web. Il metodo ha due principali limitazioni: \textit{i}) le informazioni testuali vengono usate solo per definire i pesi dei link, di conseguenza due pagine Web condivideranno le stesse proprietà distribuzionali, ma, avendo una similarità testuale bassa, non potranno essere inserite nello stesso cluster; \textit{ii}) l'algoritmo di Clustering del grafo è NP-hard, ovvero è altamente complesso in termini di computazione.
	\\
	In \cite{lin}, l'autore propone una misura di similarità ottenuta combinando la somiglianza di tipo testuale, di co-citazione, di bibliografia e della struttura ad hyperlink che interconnettono pagine dello stesso sito Web. In questo modo, due pagine che hanno una similarità di struttura ad hyperlink appariranno più volte all'interno della collezione dei link.  Le combinazioni delle varie similarità, ancora oggi, sono ancora un problema aperto.
\end{itemize}

\section{Altre metodologie di Clustering}
Gli algoritmi di Clustering basati sulla struttura ad hyperlink considerano solo relazioni dirette tra i vicini, senza analizzare la struttura globale del grafo del sito Web. In \cite{gornerup,zhou,tang2015line} gli autori sostengono che la similarità tra i nodi di due grafi può essere rappresentata in termini di somiglianza dei loro rispettivi contesti: in altri termini, come condividono i nodi vicini.
\\
In \cite{zhou} viene proposto un algoritmo di Clustering che si concentra sulla struttura topologica di un grafo e sulle proprietà dei nodi, che possono essere testuali o relazionali. Un insieme di nodi ed archi attributi vengono aggiunti al grafo originale. Così facendo, la similarità degli attributi è trasformata in base alla vicinanza dei vertici nei grafi: due vertici che condividono un attributo sono collegati da uno di tipo attributo. Nonostante l'algoritmo possa combinare sia le informazioni strutturali che di contenuto, usando una comune rappresentazione, non può essere utilizzato a dati che hanno valori numerici (e.g. tf-idf) o attributi categorici aventi un gran numero di valori distinti.
\\
In \cite{tang2015line} viene proposto un metodo di embedding chiamato Line. Questa metodologia sfrutta la rete neurale per generare una rappresentazione vettoriale densa e a bassa dimensionalità dei nodi del grafo. Line \cite{tang2015line} ottimizza una funzione che incorpora le strutture locali e globali della rete. Una limitazione di questa metodologia è che vengono ignorati i nodi attributo (e.g. contenuto testuale). Di conseguenza, l'operazione di Clustering basata su embedding generati da Line potrebbero essere difficoltosi in grafi senza sufficienti hyperlink interni ed esterni, ma caratterizzati da ricchi contenuti testuali.

\subsection{Combinazione di embeddings}
Recenti sperimentazioni hanno esaminato vari approcci di generazione di embedding per capire i punti di forza e le debolezze di ognuno. Altre aree di ricerca del Machine Learning hanno scoperto che, combinando varie tecniche, è possibile ottenere risultati eccellenti.
\\
In questo contesto, gli autori di \cite{garden} hanno esplorato varie tipologie di composizioni di embedding, dimostrando che i vari metodi di combinazione dei vettori degli embedding possono produrre spazi vettoriali ibridi che forniscono risultati aventi una bontà significativa. Nello specifico, hanno cercato di capire se si ottengono risultati migliori  effettuando una semplice addizione o una concatenazione tra i vettori. Gli spazi vettoriali sono stati prodotti da due algoritmi differenti di Machine Learning:
\begin{itemize}
	\item \textbf{DVRS}. E' un metodo per generare rappresentazioni vettoriali semantiche. Ogni parola è rappresentata da due vettori: un vettore ambientale fisso $e(i)$ viene generato casualmente assegnando ad ogni elemento del vettore un valore compreso tra $[-1,1)$; il vettore lessicale $l(i)$ cattura, invece, il significato della parola, che viene aggiornato durante l'apprendimento. Una volta che il documento viene processato, il vettore lessicale di ogni parola viene aggiornato in base sia al contesto di paragrafo $c(k)$, sia al contesto di ordine della frase $o(k)$. Rispettivamente:
	\begin{equation}
		c(k) = \sum_{i=1}^{n} e(i), i \neq k
	\end{equation}
	\begin{equation}
		o(k) = \sum_{j=-4}^{4} s(j) * e(k + j)
	\end{equation}
	dove $j \neq 0$ e $0 < (k + j) \leq n $.
	\item \textbf{Word2Vec}. E' un algoritmo di Word Embedding che trasforma parole in Feature Vectors. Per approfondimenti, vedere la Sezione \label{word2vec}.
\end{itemize}
I risultati riportati da \cite{garden} mostrano come la combinazione dei vettori di DVRS e di Word2Vec porta ad un incremento della bontà dei risultati.